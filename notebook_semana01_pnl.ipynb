{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Etuarda/EstudosTSMinasProgramam25-2/blob/main/notebook_semana01_pnl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_header"
      },
      "source": [
        "# Entrega 1 - Pré-processamento e Análise Morfossintática\n",
        "\n",
        "**Curso:** Processamento de Linguagem Natural  \n",
        "**Aluno:** Eduarda Silva Santos\n",
        "**Data:** 16/01/2026\n",
        "\n",
        "---\n",
        "\n",
        "## Objetivo\n",
        "\n",
        "Implementar um **pipeline de pré-processamento e análise morfossintática** que será reutilizado no projeto final do chatbot de e-commerce.\n",
        "\n",
        "## Instruções\n",
        "\n",
        "1. Complete todos os exercícios marcados com `# === SEU CÓDIGO AQUI ===`\n",
        "2. **Não modifique** os nomes das funções ou variáveis indicadas\n",
        "3. Execute todas as células em ordem antes de submeter\n",
        "4. As funções implementadas serão reutilizadas nas próximas entregas\n",
        "\n",
        "## Critérios de Avaliação\n",
        "\n",
        "| Questão | Pontos | Descrição |\n",
        "|---------|--------|------------|\n",
        "| Q1 | 8 | Limpeza básica de texto |\n",
        "| Q2 | 8 | Tokenização com NLTK |\n",
        "| Q3 | 8 | Remoção de stopwords |\n",
        "| Q4 | 8 | Stemming RSLP |\n",
        "| Q5 | 10 | Pipeline completo |\n",
        "| Q6 | 10 | Análise de frequência |\n",
        "| Q7 | 10 | Processamento em lote |\n",
        "| Q8 | 8 | Extração de POS tags (spaCy) |\n",
        "| Q9 | 8 | Extração de substantivos (spaCy) |\n",
        "| Q10 | 7 | Extração de adjetivos (spaCy) |\n",
        "| Q11 | 7 | Extração de verbos (spaCy) |\n",
        "| Q12 | 8 | Função integrada final |\n",
        "| **Total** | **100** | |\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Utilizaremos o dataset **B2W-Reviews01** com reviews de e-commerce brasileiro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_setup_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Setup Inicial\n",
        "\n",
        "Execute as células abaixo para configurar o ambiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_setup_install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4add414-92f7-447f-8fd1-058281529e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Dependências instaladas!\n"
          ]
        }
      ],
      "source": [
        "# === INSTALAÇÃO DE DEPENDÊNCIAS ===\n",
        "# Não modifique esta célula\n",
        "\n",
        "!pip install nltk pandas numpy matplotlib wordcloud spacy --quiet\n",
        "!python -m spacy download pt_core_news_sm --quiet\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('rslp', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "\n",
        "print(\"Dependências instaladas!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_setup_imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33b76009-669a-4900-b80d-4d073d5323ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imports realizados!\n",
            "NLTK versão: 3.9.1\n",
            "spaCy versão: 3.8.11\n"
          ]
        }
      ],
      "source": [
        "# === IMPORTS ===\n",
        "# Não modifique esta célula\n",
        "\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "# spaCy\n",
        "import spacy\n",
        "nlp_spacy = spacy.load('pt_core_news_sm')\n",
        "\n",
        "# Configurações\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Constantes do exercício\n",
        "SEED_AVALIACAO = 42\n",
        "np.random.seed(SEED_AVALIACAO)\n",
        "\n",
        "print(\"Imports realizados!\")\n",
        "print(f\"NLTK versão: {nltk.__version__}\")\n",
        "print(f\"spaCy versão: {spacy.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_setup_data",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "4fa9dc07-11ee-429f-ec18-d47903f687a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset carregado: 980 reviews\n",
            "Colunas: ['submission_date', 'reviewer_id', 'product_id', 'product_name', 'product_brand', 'site_category_lv1', 'site_category_lv2', 'review_title', 'overall_rating', 'recommend_to_a_friend', 'review_text', 'reviewer_birth_year', 'reviewer_gender', 'reviewer_state']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         review_text  overall_rating\n",
              "0  Estou contente com a compra entrega rápida o ú...               4\n",
              "1  Por apenas R$1994.20,eu consegui comprar esse ...               4\n",
              "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...               4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd10b68d-31ef-4142-a321-fd38959221a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>overall_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd10b68d-31ef-4142-a321-fd38959221a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd10b68d-31ef-4142-a321-fd38959221a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd10b68d-31ef-4142-a321-fd38959221a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_reviews_b2w[['review_text', 'overall_rating']]\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"review_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Estou contente com a compra entrega r\\u00e1pida o \\u00fanico problema com as Americanas \\u00e9 se houver troca ou devolu\\u00e7\\u00e3o do produto o consumidor tem problemas com espera.\",\n          \"Por apenas R$1994.20,eu consegui comprar esse lindo copo de acr\\u00edlico.\",\n          \"SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANELAS EL\\u00c9TRICAS.  COSTUMO USAR OUTRA PANELA PARA COZIMENTO DE ARROZ (JAPONESA), MAS LEVA MUITO TEMPO,  +/- 50 MINUTOS.  NESSA PANELA  \\u00c9 MUITO MAIS R\\u00c1PIDO, EXATAMENTE 6 MINUTOS.    EU RECOMENDO.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 4,\n        \"max\": 4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# === CARREGAR DATASET ===\n",
        "# Não modifique esta célula\n",
        "\n",
        "URL_DATASET_B2W = \"https://raw.githubusercontent.com/americanas-tech/b2w-reviews01/main/B2W-Reviews01.csv\"\n",
        "\n",
        "df_reviews_b2w = pd.read_csv(URL_DATASET_B2W, nrows=1000)\n",
        "df_reviews_b2w = df_reviews_b2w.dropna(subset=['review_text'])\n",
        "df_reviews_b2w = df_reviews_b2w.reset_index(drop=True)\n",
        "\n",
        "print(f\"Dataset carregado: {len(df_reviews_b2w)} reviews\")\n",
        "print(f\"Colunas: {list(df_reviews_b2w.columns)}\")\n",
        "\n",
        "# Exibir amostra\n",
        "df_reviews_b2w[['review_text', 'overall_rating']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_setup_samples",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e45753f-28c8-488d-cc20-5ebd48d16491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras de validação definidas!\n",
            "\n",
            "Textos NLTK:\n",
            "  Q1 (índice 7): 'Produto excelente qualidade boa câmera desenvolvimento do Android com rapidez...'\n",
            "  Q2 (índice 13): 'Esse celular não vale nada a bateria não vale nada descarrega sozinha quando est...'\n",
            "\n",
            "Textos spaCy:\n",
            "  Q8 (índice 17): 'nao tenho nada a reclamar, bom atendimento e entrega dentro do combinado....'\n",
            "  Q9 (índice 29): 'Uma tela impecável. Se sua prioridade é tela e câmera, esse é o cara. O ponto fr...'\n"
          ]
        }
      ],
      "source": [
        "# === AMOSTRAS PARA EXERCÍCIOS ===\n",
        "# Não modifique esta célula\n",
        "\n",
        "# Textos específicos para validação (NLTK)\n",
        "TEXTO_VALIDACAO_Q1 = df_reviews_b2w['review_text'].iloc[7]\n",
        "TEXTO_VALIDACAO_Q2 = df_reviews_b2w['review_text'].iloc[13]\n",
        "TEXTO_VALIDACAO_Q5 = df_reviews_b2w['review_text'].iloc[21]\n",
        "\n",
        "# Índices para processamento em lote\n",
        "INDICES_LOTE_Q7 = [3, 8, 15, 22, 31, 47, 56, 63, 78, 89]\n",
        "REVIEWS_LOTE_Q7 = df_reviews_b2w['review_text'].iloc[INDICES_LOTE_Q7].tolist()\n",
        "\n",
        "# Textos específicos para validação (spaCy)\n",
        "TEXTO_VALIDACAO_Q8 = df_reviews_b2w['review_text'].iloc[17]\n",
        "TEXTO_VALIDACAO_Q9 = df_reviews_b2w['review_text'].iloc[29]\n",
        "TEXTO_VALIDACAO_Q10 = df_reviews_b2w['review_text'].iloc[41]\n",
        "TEXTO_VALIDACAO_Q11 = df_reviews_b2w['review_text'].iloc[53]\n",
        "\n",
        "print(\"Amostras de validação definidas!\")\n",
        "print(f\"\\nTextos NLTK:\")\n",
        "print(f\"  Q1 (índice 7): '{TEXTO_VALIDACAO_Q1[:80]}...'\")\n",
        "print(f\"  Q2 (índice 13): '{TEXTO_VALIDACAO_Q2[:80]}...'\")\n",
        "print(f\"\\nTextos spaCy:\")\n",
        "print(f\"  Q8 (índice 17): '{TEXTO_VALIDACAO_Q8[:80]}...'\")\n",
        "print(f\"  Q9 (índice 29): '{TEXTO_VALIDACAO_Q9[:80]}...'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_parte1_header"
      },
      "source": [
        "---\n",
        "\n",
        "# PARTE 1: Pré-processamento com NLTK (54 pontos)\n",
        "\n",
        "Nesta parte, você implementará funções de pré-processamento usando NLTK e regex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q1_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 1: Limpeza Básica de Texto (8 pontos)\n",
        "\n",
        "Implemente a função `limpar_texto` que realiza as seguintes operações:\n",
        "\n",
        "1. Converte o texto para **minúsculas**\n",
        "2. Remove **URLs** (padrões http://, https://, www.)\n",
        "3. Remove **emails** (padrões com @)\n",
        "4. Remove **números** isolados\n",
        "5. Remove **pontuação** excessiva (mantendo espaços)\n",
        "6. Remove **espaços múltiplos** (substituir por espaço único)\n",
        "7. Remove espaços no **início e fim** do texto\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a ser limpo\n",
        "\n",
        "**Retorno:**\n",
        "- `str`: Texto limpo\n",
        "\n",
        "**Dica:** Use expressões regulares (`re.sub`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q1_answer"
      },
      "outputs": [],
      "source": [
        "def limpar_texto(texto: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza limpeza básica de texto para pré-processamento.\n",
        "\n",
        "    Operações:\n",
        "    - Converte para minúsculas\n",
        "    - Remove URLs, emails, números isolados\n",
        "    - Remove pontuação e espaços extras\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto original\n",
        "\n",
        "    Retorna:\n",
        "        str: Texto limpo\n",
        "\n",
        "    Exemplo:\n",
        "        >>> limpar_texto(\"PRODUTO BOM!!! Visite http://loja.com\")\n",
        "        'produto bom visite'\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return \"\"\n",
        "\n",
        "    # 1) minúsculas\n",
        "    texto = str(texto).lower()\n",
        "\n",
        "    # 2) remover URLs (http://, https://, www.)\n",
        "    texto = re.sub(r\"\\bhttps?://\\S+\\b\", \" \", texto)\n",
        "    texto = re.sub(r\"\\bwww\\.\\S+\\b\", \" \", texto)\n",
        "\n",
        "    # 3) remover emails (com @)\n",
        "    texto = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \" \", texto)\n",
        "\n",
        "    # 4) remover números isolados\n",
        "    texto = re.sub(r\"\\b\\d+\\b\", \" \", texto)\n",
        "\n",
        "    # 5) remover pontuação (mantendo espaços)\n",
        "    texto = re.sub(rf\"[{re.escape(string.punctuation)}]\", \" \", texto)\n",
        "\n",
        "    # 6) remover espaços múltiplos (virar um só) + 7) trim\n",
        "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
        "\n",
        "    return texto\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "texto_limpo_q1 = limpar_texto(TEXTO_VALIDACAO_Q1)\n",
        "num_palavras_q1 = len(texto_limpo_q1.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q1_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9c041c-616d-4d11-8a0d-5073e45e9d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q1: limpar_texto\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 7):\n",
            "  'Produto excelente qualidade boa câmera desenvolvimento do Android com rapidez'\n",
            "\n",
            "Texto limpo:\n",
            "  'produto excelente qualidade boa câmera desenvolvimento do android com rapidez'\n",
            "\n",
            "Estatísticas:\n",
            "  Palavras: 10\n",
            "  Tamanho: 77 caracteres\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q1 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q1: limpar_texto\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 7):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q1}'\")\n",
        "print(f\"\\nTexto limpo:\")\n",
        "print(f\"  '{texto_limpo_q1}'\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Palavras: {num_palavras_q1}\")\n",
        "print(f\"  Tamanho: {len(texto_limpo_q1)} caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q2_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 2: Tokenização com NLTK (8 pontos)\n",
        "\n",
        "Implemente a função `tokenizar` que divide o texto em tokens (palavras).\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use `word_tokenize` do NLTK com `language='portuguese'`\n",
        "2. Retorne apenas tokens **alfabéticos** (sem números ou pontuação)\n",
        "3. Tokens devem estar em **minúsculas**\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a ser tokenizado\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de tokens\n",
        "\n",
        "**Dica:** Use `str.isalpha()` para verificar se token é alfabético."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q2_answer"
      },
      "outputs": [],
      "source": [
        "def tokenizar(texto: str) -> list:\n",
        "    \"\"\"\n",
        "    Tokeniza texto usando NLTK word_tokenize.\n",
        "\n",
        "    Retorna apenas tokens alfabéticos em minúsculas.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a tokenizar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de tokens (palavras)\n",
        "\n",
        "    Exemplo:\n",
        "        >>> tokenizar(\"Produto bom! Entrega rápida.\")\n",
        "        ['produto', 'bom', 'entrega', 'rápida']\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # Tokenização com NLTK (português)\n",
        "    tokens = word_tokenize(str(texto), language=\"portuguese\")\n",
        "\n",
        "    # Manter apenas tokens alfabéticos e converter para minúsculas\n",
        "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "tokens_q2 = tokenizar(TEXTO_VALIDACAO_Q2)\n",
        "num_tokens_q2 = len(tokens_q2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q2_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c29e34c-8e1e-4e1e-f775-8b3383677906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q2: tokenizar\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 13):\n",
            "  'Esse celular não vale nada a bateria não vale nada descarrega sozinha quando estar usando esquenta tanto que faz medo espludi foi a pior compra da minha vida se eu tivesse condições quebrava ele em mil pedaços e comprava outro de qualquer marca menos Motorola'\n",
            "\n",
            "Tokens gerados (45 tokens):\n",
            "  ['esse', 'celular', 'não', 'vale', 'nada', 'a', 'bateria', 'não', 'vale', 'nada', 'descarrega', 'sozinha', 'quando', 'estar', 'usando', 'esquenta', 'tanto', 'que', 'faz', 'medo', 'espludi', 'foi', 'a', 'pior', 'compra', 'da', 'minha', 'vida', 'se', 'eu', 'tivesse', 'condições', 'quebrava', 'ele', 'em', 'mil', 'pedaços', 'e', 'comprava', 'outro', 'de', 'qualquer', 'marca', 'menos', 'motorola']\n",
            "\n",
            "Primeiros 10 tokens:\n",
            "  ['esse', 'celular', 'não', 'vale', 'nada', 'a', 'bateria', 'não', 'vale', 'nada']\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q2 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q2: tokenizar\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 13):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q2}'\")\n",
        "print(f\"\\nTokens gerados ({num_tokens_q2} tokens):\")\n",
        "print(f\"  {tokens_q2}\")\n",
        "print(f\"\\nPrimeiros 10 tokens:\")\n",
        "print(f\"  {tokens_q2[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q3_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 3: Remoção de Stopwords (8 pontos)\n",
        "\n",
        "Implemente a função `remover_stopwords` que remove palavras comuns (stopwords) de uma lista de tokens.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use a lista de stopwords do NLTK para português\n",
        "2. Mantenha apenas tokens que **não** estão na lista de stopwords\n",
        "3. Retorne os tokens na mesma ordem\n",
        "\n",
        "**Parâmetros:**\n",
        "- `tokens` (list): Lista de tokens\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de tokens sem stopwords\n",
        "\n",
        "**Dica:** Use `stopwords.words('portuguese')`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q3_answer"
      },
      "outputs": [],
      "source": [
        "def remover_stopwords(tokens: list) -> list:\n",
        "    \"\"\"\n",
        "    Remove stopwords (palavras comuns) de lista de tokens.\n",
        "\n",
        "    Usa lista de stopwords do NLTK para português.\n",
        "\n",
        "    Parâmetros:\n",
        "        tokens (list): Lista de tokens\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de tokens sem stopwords\n",
        "\n",
        "    Exemplo:\n",
        "        >>> remover_stopwords(['o', 'produto', 'é', 'bom'])\n",
        "        ['produto', 'bom']\n",
        "    \"\"\"\n",
        "    if not tokens:\n",
        "        return []\n",
        "\n",
        "    # Lista de stopwords em português\n",
        "    stopwords_pt = set(stopwords.words('portuguese'))\n",
        "\n",
        "    # Manter apenas tokens que não são stopwords, preservando a ordem\n",
        "    tokens_filtrados = [token for token in tokens if token not in stopwords_pt]\n",
        "\n",
        "    return tokens_filtrados\n",
        "\n",
        "\n",
        "# === APLICAR NOS TOKENS DA Q2 ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "tokens_sem_stopwords_q3 = remover_stopwords(tokens_q2)\n",
        "num_tokens_removidos_q3 = num_tokens_q2 - len(tokens_sem_stopwords_q3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q3_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7632c414-2285-42ca-db45-69a1c643d93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q3: remover_stopwords\n",
            "============================================================\n",
            "\n",
            "Tokens originais (45):\n",
            "  ['esse', 'celular', 'não', 'vale', 'nada', 'a', 'bateria', 'não', 'vale', 'nada', 'descarrega', 'sozinha', 'quando', 'estar', 'usando']...\n",
            "\n",
            "Tokens sem stopwords (27):\n",
            "  ['celular', 'vale', 'nada', 'bateria', 'vale', 'nada', 'descarrega', 'sozinha', 'usando', 'esquenta', 'tanto', 'faz', 'medo', 'espludi', 'pior']...\n",
            "\n",
            "Estatísticas:\n",
            "  Tokens removidos: 18\n",
            "  Taxa de remoção: 40.0%\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q3 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q3: remover_stopwords\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTokens originais ({num_tokens_q2}):\")\n",
        "print(f\"  {tokens_q2[:15]}...\")\n",
        "print(f\"\\nTokens sem stopwords ({len(tokens_sem_stopwords_q3)}):\")\n",
        "print(f\"  {tokens_sem_stopwords_q3[:15]}...\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Tokens removidos: {num_tokens_removidos_q3}\")\n",
        "print(f\"  Taxa de remoção: {num_tokens_removidos_q3/num_tokens_q2*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q4_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 4: Stemming com RSLP (8 pontos)\n",
        "\n",
        "Implemente a função `aplicar_stemming` que reduz palavras à sua raiz usando o algoritmo RSLP.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use `RSLPStemmer` do NLTK\n",
        "2. Aplique stemming em cada token da lista\n",
        "3. Retorne lista de tokens \"stemmizados\"\n",
        "\n",
        "**Parâmetros:**\n",
        "- `tokens` (list): Lista de tokens\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de tokens com stemming aplicado\n",
        "\n",
        "**Dica:** RSLP é específico para português brasileiro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q4_answer"
      },
      "outputs": [],
      "source": [
        "def aplicar_stemming(tokens: list) -> list:\n",
        "    \"\"\"\n",
        "    Aplica stemming RSLP em lista de tokens.\n",
        "\n",
        "    Reduz cada palavra à sua raiz morfológica.\n",
        "\n",
        "    Parâmetros:\n",
        "        tokens (list): Lista de tokens\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de tokens com stemming\n",
        "\n",
        "    Exemplo:\n",
        "        >>> aplicar_stemming(['produtos', 'comprando', 'vendedores'])\n",
        "        ['produt', 'compr', 'vended']\n",
        "    \"\"\"\n",
        "    if not tokens:\n",
        "        return []\n",
        "\n",
        "    # Inicializa o stemmer RSLP (português brasileiro)\n",
        "    stemmer = RSLPStemmer()\n",
        "\n",
        "    # Aplica stemming em cada token\n",
        "    tokens_stemmizados = [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "    return tokens_stemmizados\n",
        "\n",
        "\n",
        "# === APLICAR NOS TOKENS SEM STOPWORDS ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "tokens_stemming_q4 = aplicar_stemming(tokens_sem_stopwords_q3)\n",
        "tokens_unicos_q4 = len(set(tokens_stemming_q4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q4_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38de1aa5-a2a8-4b4e-b497-aeddebf5ebc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q4: aplicar_stemming\n",
            "============================================================\n",
            "\n",
            "Tokens antes (27 tokens):\n",
            "  ['celular', 'vale', 'nada', 'bateria', 'vale', 'nada', 'descarrega', 'sozinha', 'usando', 'esquenta']\n",
            "\n",
            "Tokens após stemming (27 tokens):\n",
            "  ['celul', 'val', 'nad', 'bat', 'val', 'nad', 'descarreg', 'so', 'us', 'esquent']\n",
            "\n",
            "Estatísticas:\n",
            "  Tokens únicos antes: 25\n",
            "  Tokens únicos após: 24\n",
            "  Redução de vocabulário: 1 tokens\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q4 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q4: aplicar_stemming\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTokens antes ({len(tokens_sem_stopwords_q3)} tokens):\")\n",
        "print(f\"  {tokens_sem_stopwords_q3[:10]}\")\n",
        "print(f\"\\nTokens após stemming ({len(tokens_stemming_q4)} tokens):\")\n",
        "print(f\"  {tokens_stemming_q4[:10]}\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Tokens únicos antes: {len(set(tokens_sem_stopwords_q3))}\")\n",
        "print(f\"  Tokens únicos após: {tokens_unicos_q4}\")\n",
        "print(f\"  Redução de vocabulário: {len(set(tokens_sem_stopwords_q3)) - tokens_unicos_q4} tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q5_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 5: Pipeline Completo de Pré-processamento (10 pontos)\n",
        "\n",
        "Implemente a função `preprocessar_texto` que combina todas as etapas anteriores em um pipeline único.\n",
        "\n",
        "**Pipeline:**\n",
        "1. Limpeza (`limpar_texto`)\n",
        "2. Tokenização (`tokenizar`)\n",
        "3. Remoção de stopwords (`remover_stopwords`)\n",
        "4. Stemming (`aplicar_stemming`)\n",
        "5. Juntar tokens em string (separados por espaço)\n",
        "\n",
        "**IMPORTANTE:** Você DEVE usar as funções implementadas nas questões anteriores.\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto original\n",
        "\n",
        "**Retorno:**\n",
        "- `str`: Texto pré-processado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q5_answer"
      },
      "outputs": [],
      "source": [
        "def preprocessar_texto(texto: str) -> str:\n",
        "    \"\"\"\n",
        "    Pipeline completo de pré-processamento.\n",
        "\n",
        "    Aplica todas as etapas: limpeza, tokenização,\n",
        "    remoção de stopwords e stemming.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto original\n",
        "\n",
        "    Retorna:\n",
        "        str: Texto pré-processado\n",
        "\n",
        "    Exemplo:\n",
        "        >>> preprocessar_texto(\"Os produtos chegaram rápido!\")\n",
        "        'produt cheg rapid'\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return \"\"\n",
        "\n",
        "    # 1) Limpeza básica\n",
        "    texto_limpo = limpar_texto(texto)\n",
        "\n",
        "    # 2) Tokenização\n",
        "    tokens = tokenizar(texto_limpo)\n",
        "\n",
        "    # 3) Remoção de stopwords\n",
        "    tokens_sem_stopwords = remover_stopwords(tokens)\n",
        "\n",
        "    # 4) Stemming\n",
        "    tokens_stemming = aplicar_stemming(tokens_sem_stopwords)\n",
        "\n",
        "    # 5) Juntar tokens em uma string\n",
        "    texto_preprocessado = \" \".join(tokens_stemming)\n",
        "\n",
        "    return texto_preprocessado\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "texto_preprocessado_q5 = preprocessar_texto(TEXTO_VALIDACAO_Q5)\n",
        "num_termos_finais_q5 = len(texto_preprocessado_q5.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q5_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffafd55-6a89-45de-c0d1-54b767cfdd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q5: preprocessar_texto\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 21):\n",
            "  'Pontos Positivos Painel de 10bits (isso faz toda diferença da mais de 1 bilhão de cores) Bluetooth Wi-Fi AC USB 3.0 Input Lag Baixo Painel VA, que proporciona um alto contraste. Android TV 6.0 Som da TV realmente é excepcional! (saída do auto falantes são voltados para frente) Vem 2 controles remotos  A tv realmente é formidável, valeu muito a pena ter comprado TCL.'\n",
            "\n",
            "Texto pré-processado:\n",
            "  'pont posi painel faz tod diferenç bilhã cor bluetooth wi fi ac usb input lag baix painel va proporc alt contr android tv som tv real excepc saíd aut fal volt frent vem control remot tv real formid val pen ter compr tcl'\n",
            "\n",
            "Estatísticas:\n",
            "  Termos finais: 43\n",
            "  Tamanho original: 368 caracteres\n",
            "  Tamanho processado: 218 caracteres\n",
            "  Redução: 40.8%\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q5 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q5: preprocessar_texto\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 21):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q5}'\")\n",
        "print(f\"\\nTexto pré-processado:\")\n",
        "print(f\"  '{texto_preprocessado_q5}'\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Termos finais: {num_termos_finais_q5}\")\n",
        "print(f\"  Tamanho original: {len(TEXTO_VALIDACAO_Q5)} caracteres\")\n",
        "print(f\"  Tamanho processado: {len(texto_preprocessado_q5)} caracteres\")\n",
        "print(f\"  Redução: {(1 - len(texto_preprocessado_q5)/len(TEXTO_VALIDACAO_Q5))*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q6_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 6: Análise de Frequência de Termos (10 pontos)\n",
        "\n",
        "Implemente a função `analisar_frequencia` que retorna os N termos mais frequentes em um texto.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Pré-processe o texto usando `preprocessar_texto`\n",
        "2. Conte a frequência de cada termo\n",
        "3. Retorne lista de tuplas `(termo, frequencia)` ordenada por frequência (maior → menor)\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a analisar\n",
        "- `n` (int): Número de termos mais frequentes a retornar (padrão: 10)\n",
        "\n",
        "**Retorno:**\n",
        "- `list[tuple]`: Lista de (termo, frequencia)\n",
        "\n",
        "**Dica:** Use `Counter` do módulo `collections`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q6_answer"
      },
      "outputs": [],
      "source": [
        "def analisar_frequencia(texto: str, n: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Retorna os N termos mais frequentes em um texto.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a analisar\n",
        "        n (int): Número de termos a retornar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de tuplas (termo, frequencia)\n",
        "\n",
        "    Exemplo:\n",
        "        >>> analisar_frequencia(\"produto produto bom bom bom\", n=2)\n",
        "        [('bom', 3), ('produto', 2)]\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # 1) Pré-processar o texto (pipeline completo)\n",
        "    texto_preprocessado = preprocessar_texto(texto)\n",
        "\n",
        "    if not texto_preprocessado:\n",
        "        return []\n",
        "\n",
        "    # 2) Quebrar em termos\n",
        "    termos = texto_preprocessado.split()\n",
        "\n",
        "    # 3) Contar frequência\n",
        "    contagem = Counter(termos)\n",
        "\n",
        "    # 4) Retornar os N termos mais frequentes (ordem decrescente)\n",
        "    return contagem.most_common(n)\n",
        "\n",
        "\n",
        "# === APLICAR EM MÚLTIPLOS REVIEWS ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "# Concatenar primeiros 50 reviews\n",
        "texto_analise_q6 = \" \".join(df_reviews_b2w['review_text'].iloc[:50].tolist())\n",
        "termos_frequentes_q6 = analisar_frequencia(texto_analise_q6, n=15)\n",
        "termo_mais_frequente_q6 = termos_frequentes_q6[0][0] if termos_frequentes_q6 else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q6_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2723f09d-9b2f-46f9-b76d-eb3e05bd6ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q6: analisar_frequencia\n",
            "============================================================\n",
            "\n",
            "Análise de 50 primeiros reviews\n",
            "\n",
            "Top 15 termos mais frequentes:\n",
            "   1. 'produt' → 22 ocorrências\n",
            "   2. 'compr' → 16 ocorrências\n",
            "   3. 'entreg' → 13 ocorrências\n",
            "   4. 'recom' → 9 ocorrências\n",
            "   5. 'gost' → 9 ocorrências\n",
            "   6. 'sup' → 8 ocorrências\n",
            "   7. 'praz' → 8 ocorrências\n",
            "   8. 'excel' → 8 ocorrências\n",
            "   9. 'americ' → 7 ocorrências\n",
            "  10. 'nao' → 7 ocorrências\n",
            "  11. 'outr' → 6 ocorrências\n",
            "  12. 'bom' → 6 ocorrências\n",
            "  13. 'câm' → 6 ocorrências\n",
            "  14. 'bem' → 6 ocorrências\n",
            "  15. 'parabém' → 5 ocorrências\n",
            "\n",
            "Termo mais frequente: 'produt'\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q6 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q6: analisar_frequencia\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nAnálise de 50 primeiros reviews\")\n",
        "print(f\"\\nTop 15 termos mais frequentes:\")\n",
        "for i, (termo, freq) in enumerate(termos_frequentes_q6, 1):\n",
        "    print(f\"  {i:2d}. '{termo}' → {freq} ocorrências\")\n",
        "print(f\"\\nTermo mais frequente: '{termo_mais_frequente_q6}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q7_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 7: Processamento em Lote (10 pontos)\n",
        "\n",
        "Implemente a função `processar_lote` que processa múltiplos textos de uma vez.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Receba uma lista de textos\n",
        "2. Aplique `preprocessar_texto` em cada texto\n",
        "3. Retorne lista de textos pré-processados na mesma ordem\n",
        "\n",
        "**Parâmetros:**\n",
        "- `lista_textos` (list): Lista de textos originais\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de textos pré-processados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q7_answer"
      },
      "outputs": [],
      "source": [
        "def processar_lote(lista_textos: list) -> list:\n",
        "    \"\"\"\n",
        "    Processa múltiplos textos em lote.\n",
        "\n",
        "    Aplica preprocessar_texto em cada texto da lista.\n",
        "\n",
        "    Parâmetros:\n",
        "        lista_textos (list): Lista de textos originais\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de textos pré-processados\n",
        "\n",
        "    Exemplo:\n",
        "        >>> processar_lote([\"Texto 1\", \"Texto 2\"])\n",
        "        ['text', 'text']\n",
        "    \"\"\"\n",
        "    if not lista_textos:\n",
        "        return []\n",
        "\n",
        "    # Aplicar o pipeline de pré-processamento em cada texto, mantendo a ordem\n",
        "    textos_processados = [preprocessar_texto(texto) for texto in lista_textos]\n",
        "\n",
        "    return textos_processados\n",
        "\n",
        "\n",
        "# === APLICAR NO LOTE DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "reviews_processadas_q7 = processar_lote(REVIEWS_LOTE_Q7)\n",
        "\n",
        "# Calcular média de termos por review\n",
        "num_termos_por_review = [len(texto.split()) for texto in reviews_processadas_q7]\n",
        "media_termos_q7 = sum(num_termos_por_review) / len(num_termos_por_review)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q7_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "378070d8-a952-4729-b770-5c3ecb499e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q7: processar_lote\n",
            "============================================================\n",
            "\n",
            "Lote de entrada:\n",
            "  Número de reviews: 10\n",
            "  Índices: [3, 8, 15, 22, 31, 47, 56, 63, 78, 89]\n",
            "\n",
            "Resultados:\n",
            "  Reviews processadas: 10\n",
            "  Média de termos/review: 9.20\n",
            "\n",
            "Amostra (3 primeiras):\n",
            "\n",
            "  [3] Original:   'MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS DETALHES QUE TÊ...'\n",
            "      Processado: 'filh amou parec verdad tant detalh têm...'\n",
            "\n",
            "  [8] Original:   'O barulho e minimo e o vento é bem forte na velocidade 2...'\n",
            "      Processado: 'barulh min vent bem fort veloc...'\n",
            "\n",
            "  [15] Original:   'a mochila nao esta fechando direito por isso nao recomendo s...'\n",
            "      Processado: 'mochil nao fech direit nao recom filh nao deix suj ia devolv...'\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q7 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q7: processar_lote\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verificar lote de entrada\n",
        "print(f\"\\nLote de entrada:\")\n",
        "print(f\"  Número de reviews: {len(REVIEWS_LOTE_Q7)}\")\n",
        "print(f\"  Índices: {INDICES_LOTE_Q7}\")\n",
        "\n",
        "# Verificar saída\n",
        "print(f\"\\nResultados:\")\n",
        "print(f\"  Reviews processadas: {len(reviews_processadas_q7)}\")\n",
        "print(f\"  Média de termos/review: {media_termos_q7:.2f}\")\n",
        "\n",
        "# Exibir amostra\n",
        "print(f\"\\nAmostra (3 primeiras):\")\n",
        "for i in range(3):\n",
        "    original = REVIEWS_LOTE_Q7[i][:60] + \"...\"\n",
        "    processado = reviews_processadas_q7[i][:60] + \"...\"\n",
        "    print(f\"\\n  [{INDICES_LOTE_Q7[i]}] Original:   '{original}'\")\n",
        "    print(f\"      Processado: '{processado}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_parte2_header"
      },
      "source": [
        "---\n",
        "\n",
        "# PARTE 2: Análise Morfossintática com spaCy (30 pontos)\n",
        "\n",
        "Nesta parte, você implementará funções de análise linguística usando spaCy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q8_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 8: Extração de POS Tags (8 pontos)\n",
        "\n",
        "Implemente a função `extrair_pos_tags` que retorna os POS tags (classes gramaticais) de cada token.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use o modelo spaCy `nlp_spacy` (já carregado)\n",
        "2. Para cada token, extraia: texto, POS tag e lema\n",
        "3. Retorne lista de tuplas `(texto, pos, lema)`\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a analisar\n",
        "\n",
        "**Retorno:**\n",
        "- `list[tuple]`: Lista de (texto, pos, lema)\n",
        "\n",
        "**Dica:** Use `token.text`, `token.pos_`, `token.lemma_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q8_answer"
      },
      "outputs": [],
      "source": [
        "def extrair_pos_tags(texto: str) -> list:\n",
        "    \"\"\"\n",
        "    Extrai POS tags de cada token usando spaCy.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a analisar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de tuplas (texto, pos, lema)\n",
        "\n",
        "    Exemplo:\n",
        "        >>> extrair_pos_tags(\"O produto é bom\")\n",
        "        [('O', 'DET', 'o'), ('produto', 'NOUN', 'produto'), ...]\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # Processar texto com o modelo spaCy já carregado\n",
        "    doc = nlp_spacy(str(texto))\n",
        "\n",
        "    # Extrair (texto, POS tag, lema) de cada token\n",
        "    pos_tags = [(token.text, token.pos_, token.lemma_) for token in doc]\n",
        "\n",
        "    return pos_tags\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "pos_tags_q8 = extrair_pos_tags(TEXTO_VALIDACAO_Q8)\n",
        "num_tokens_q8 = len(pos_tags_q8)\n",
        "\n",
        "# Contar distribuição de POS\n",
        "pos_counts_q8 = Counter([tag[1] for tag in pos_tags_q8])\n",
        "pos_mais_frequente_q8 = pos_counts_q8.most_common(1)[0][0] if pos_counts_q8 else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q8_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26408b4-3aa7-4585-ec4a-6e9831495d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q8: extrair_pos_tags\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 17):\n",
            "  'nao tenho nada a reclamar, bom atendimento e entrega dentro do combinado.'\n",
            "\n",
            "POS tags extraídos (14 tokens):\n",
            "   1. 'nao' → POS: SCONJ  | Lema: 'nao'\n",
            "   2. 'tenho' → POS: VERB   | Lema: 'ter'\n",
            "   3. 'nada' → POS: PRON   | Lema: 'nada'\n",
            "   4. 'a' → POS: SCONJ  | Lema: 'a'\n",
            "   5. 'reclamar' → POS: VERB   | Lema: 'reclamar'\n",
            "   6. ',' → POS: PUNCT  | Lema: ','\n",
            "   7. 'bom' → POS: ADJ    | Lema: 'bom'\n",
            "   8. 'atendimento' → POS: NOUN   | Lema: 'atendimento'\n",
            "   9. 'e' → POS: CCONJ  | Lema: 'e'\n",
            "  10. 'entrega' → POS: VERB   | Lema: 'entregar'\n",
            "\n",
            "Distribuição de POS:\n",
            "  VERB: 3 (21.4%)\n",
            "  SCONJ: 2 (14.3%)\n",
            "  PUNCT: 2 (14.3%)\n",
            "  NOUN: 2 (14.3%)\n",
            "  PRON: 1 (7.1%)\n",
            "\n",
            "POS mais frequente: VERB\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q8 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q8: extrair_pos_tags\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 17):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q8}'\")\n",
        "print(f\"\\nPOS tags extraídos ({num_tokens_q8} tokens):\")\n",
        "for i, (texto, pos, lema) in enumerate(pos_tags_q8[:10]):\n",
        "    print(f\"  {i+1:2d}. '{texto}' → POS: {pos:6s} | Lema: '{lema}'\")\n",
        "print(f\"\\nDistribuição de POS:\")\n",
        "for pos, count in pos_counts_q8.most_common(5):\n",
        "    print(f\"  {pos}: {count} ({count/num_tokens_q8*100:.1f}%)\")\n",
        "print(f\"\\nPOS mais frequente: {pos_mais_frequente_q8}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q9_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 9: Extração de Substantivos (8 pontos)\n",
        "\n",
        "Implemente a função `extrair_substantivos` que retorna apenas os substantivos (NOUN) de um texto.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use o modelo spaCy `nlp_spacy`\n",
        "2. Filtre tokens com `pos_ == 'NOUN'`\n",
        "3. Retorne os **lemas** dos substantivos (forma canônica)\n",
        "4. Converta para minúsculas\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a analisar\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de lemas dos substantivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q9_answer"
      },
      "outputs": [],
      "source": [
        "def extrair_substantivos(texto: str) -> list:\n",
        "    \"\"\"\n",
        "    Extrai substantivos (lemas) de um texto.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a analisar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de lemas dos substantivos\n",
        "\n",
        "    Exemplo:\n",
        "        >>> extrair_substantivos(\"Os produtos chegaram ontem\")\n",
        "        ['produto']\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # Processar texto com spaCy\n",
        "    doc = nlp_spacy(str(texto))\n",
        "\n",
        "    # Filtrar apenas substantivos (NOUN), retornar lemas em minúsculas\n",
        "    substantivos = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
        "\n",
        "    return substantivos\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "substantivos_q9 = extrair_substantivos(TEXTO_VALIDACAO_Q9)\n",
        "num_substantivos_q9 = len(substantivos_q9)\n",
        "substantivos_unicos_q9 = len(set(substantivos_q9))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q9_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec10873-92e8-4bc1-cd23-a85e4990146c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q9: extrair_substantivos\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 29):\n",
            "  'Uma tela impecável. Se sua prioridade é tela e câmera, esse é o cara. O ponto fraco fica por conta do armazenamento, apenas 16GB, e pela câmera frontal, de apenas 5Mpixels sem flash. No entanto, a câmera principal de 13Mpixels é perfeita.'\n",
            "\n",
            "Substantivos extraídos (10):\n",
            "  ['tela', 'prioridade', 'cara', 'ponto', 'conta', 'armazenamento', 'câmera', 'flash', 'entanto', 'câmera']\n",
            "\n",
            "Estatísticas:\n",
            "  Total de substantivos: 10\n",
            "  Substantivos únicos: 9\n",
            "\n",
            "Substantivos mais frequentes:\n",
            "  'câmera': 2\n",
            "  'tela': 1\n",
            "  'prioridade': 1\n",
            "  'cara': 1\n",
            "  'ponto': 1\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q9 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q9: extrair_substantivos\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 29):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q9}'\")\n",
        "print(f\"\\nSubstantivos extraídos ({num_substantivos_q9}):\")\n",
        "print(f\"  {substantivos_q9}\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Total de substantivos: {num_substantivos_q9}\")\n",
        "print(f\"  Substantivos únicos: {substantivos_unicos_q9}\")\n",
        "if substantivos_q9:\n",
        "    freq_subst = Counter(substantivos_q9)\n",
        "    print(f\"\\nSubstantivos mais frequentes:\")\n",
        "    for subst, count in freq_subst.most_common(5):\n",
        "        print(f\"  '{subst}': {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q10_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 10: Extração de Adjetivos (7 pontos)\n",
        "\n",
        "Implemente a função `extrair_adjetivos` que retorna apenas os adjetivos (ADJ) de um texto.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use o modelo spaCy `nlp_spacy`\n",
        "2. Filtre tokens com `pos_ == 'ADJ'`\n",
        "3. Retorne os **lemas** dos adjetivos\n",
        "4. Converta para minúsculas\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a analisar\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de lemas dos adjetivos\n",
        "\n",
        "**Dica:** Adjetivos são importantes para análise de sentimento!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q10_answer"
      },
      "outputs": [],
      "source": [
        "def extrair_adjetivos(texto: str) -> list:\n",
        "    \"\"\"\n",
        "    Extrai adjetivos (lemas) de um texto.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a analisar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de lemas dos adjetivos\n",
        "\n",
        "    Exemplo:\n",
        "        >>> extrair_adjetivos(\"O produto é muito bom e rápido\")\n",
        "        ['bom', 'rápido']\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # Processar texto com o modelo spaCy\n",
        "    doc = nlp_spacy(str(texto))\n",
        "\n",
        "    # Filtrar apenas adjetivos (ADJ), retornar lemas em minúsculas\n",
        "    adjetivos = [token.lemma_.lower() for token in doc if token.pos_ == \"ADJ\"]\n",
        "\n",
        "    return adjetivos\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "adjetivos_q10 = extrair_adjetivos(TEXTO_VALIDACAO_Q10)\n",
        "num_adjetivos_q10 = len(adjetivos_q10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q10_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a6f26b-b9f6-48b3-cae1-899820f64f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q10: extrair_adjetivos\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 41):\n",
            "  'Fiquei satisfeito com a segurança e garantia de toda transação, entretanto fiz outra compra no dia 29/11 e até hoje não foi entregue. O que diferencia uma compra da outra com relação a entrega?'\n",
            "\n",
            "Adjetivos extraídos (0):\n",
            "  []\n",
            "\n",
            "Estatísticas:\n",
            "  Total de adjetivos: 0\n",
            "  Adjetivos únicos: 0\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q10 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q10: extrair_adjetivos\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 41):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q10}'\")\n",
        "print(f\"\\nAdjetivos extraídos ({num_adjetivos_q10}):\")\n",
        "print(f\"  {adjetivos_q10}\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Total de adjetivos: {num_adjetivos_q10}\")\n",
        "print(f\"  Adjetivos únicos: {len(set(adjetivos_q10))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q11_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 11: Extração de Verbos (7 pontos)\n",
        "\n",
        "Implemente a função `extrair_verbos` que retorna apenas os verbos (VERB) de um texto.\n",
        "\n",
        "**Requisitos:**\n",
        "1. Use o modelo spaCy `nlp_spacy`\n",
        "2. Filtre tokens com `pos_ == 'VERB'`\n",
        "3. Retorne os **lemas** dos verbos (forma infinitiva)\n",
        "4. Converta para minúsculas\n",
        "\n",
        "**Parâmetros:**\n",
        "- `texto` (str): Texto a analisar\n",
        "\n",
        "**Retorno:**\n",
        "- `list[str]`: Lista de lemas dos verbos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q11_answer"
      },
      "outputs": [],
      "source": [
        "def extrair_verbos(texto: str) -> list:\n",
        "    \"\"\"\n",
        "    Extrai verbos (lemas no infinitivo) de um texto.\n",
        "\n",
        "    Parâmetros:\n",
        "        texto (str): Texto a analisar\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de lemas dos verbos\n",
        "\n",
        "    Exemplo:\n",
        "        >>> extrair_verbos(\"O cliente comprou e recomendou o produto\")\n",
        "        ['comprar', 'recomendar']\n",
        "    \"\"\"\n",
        "    if texto is None:\n",
        "        return []\n",
        "\n",
        "    # Processar texto com o modelo spaCy\n",
        "    doc = nlp_spacy(str(texto))\n",
        "\n",
        "    # Filtrar apenas verbos (VERB), retornar lemas em minúsculas\n",
        "    verbos = [token.lemma_.lower() for token in doc if token.pos_ == \"VERB\"]\n",
        "\n",
        "    return verbos\n",
        "\n",
        "\n",
        "# === APLICAR NO TEXTO DE VALIDAÇÃO ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "verbos_q11 = extrair_verbos(TEXTO_VALIDACAO_Q11)\n",
        "num_verbos_q11 = len(verbos_q11)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q11_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832424fb-f218-4f38-f72f-cc6a09faa7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q11: extrair_verbos\n",
            "============================================================\n",
            "\n",
            "Texto original (índice 53):\n",
            "  'Gostei do produto! Valeu a pena a compra. Atendeu ao objetivo para o qual foi adquirido!'\n",
            "\n",
            "Verbos extraídos (4):\n",
            "  ['gostei', 'valer', 'atendeu', 'adquirir']\n",
            "\n",
            "Estatísticas:\n",
            "  Total de verbos: 4\n",
            "  Verbos únicos: 4\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q11 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q11: extrair_verbos\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTexto original (índice 53):\")\n",
        "print(f\"  '{TEXTO_VALIDACAO_Q11}'\")\n",
        "print(f\"\\nVerbos extraídos ({num_verbos_q11}):\")\n",
        "print(f\"  {verbos_q11}\")\n",
        "print(f\"\\nEstatísticas:\")\n",
        "print(f\"  Total de verbos: {num_verbos_q11}\")\n",
        "print(f\"  Verbos únicos: {len(set(verbos_q11))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_q12_header"
      },
      "source": [
        "---\n",
        "\n",
        "## Questão 12: Função Integrada Final (8 pontos)\n",
        "\n",
        "Implemente a função `criar_pipeline_preprocessamento` que retorna um **dicionário** com todas as funções de pré-processamento e análise, permitindo fácil reutilização.\n",
        "\n",
        "O dicionário deve conter as seguintes chaves:\n",
        "- `'limpar'`: referência para a função `limpar_texto`\n",
        "- `'tokenizar'`: referência para a função `tokenizar`\n",
        "- `'remover_stopwords'`: referência para a função `remover_stopwords`\n",
        "- `'aplicar_stemming'`: referência para a função `aplicar_stemming`\n",
        "- `'preprocessar'`: referência para a função `preprocessar_texto`\n",
        "- `'processar_lote'`: referência para a função `processar_lote`\n",
        "- `'analisar_frequencia'`: referência para a função `analisar_frequencia`\n",
        "- `'extrair_pos_tags'`: referência para a função `extrair_pos_tags`\n",
        "- `'extrair_substantivos'`: referência para a função `extrair_substantivos`\n",
        "- `'extrair_adjetivos'`: referência para a função `extrair_adjetivos`\n",
        "- `'extrair_verbos'`: referência para a função `extrair_verbos`\n",
        "\n",
        "**IMPORTANTE:** Esta função será usada para importar o pipeline no projeto final!\n",
        "\n",
        "**Retorno:**\n",
        "- `dict`: Dicionário com as funções do pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q12_answer"
      },
      "outputs": [],
      "source": [
        "def criar_pipeline_preprocessamento() -> dict:\n",
        "    \"\"\"\n",
        "    Cria dicionário com todas as funções de pré-processamento e análise.\n",
        "\n",
        "    Este pipeline será reutilizado no projeto final do chatbot.\n",
        "\n",
        "    Retorna:\n",
        "        dict: Dicionário com funções do pipeline\n",
        "\n",
        "    Exemplo:\n",
        "        >>> pipeline = criar_pipeline_preprocessamento()\n",
        "        >>> pipeline['preprocessar']('Texto de teste')\n",
        "        'text test'\n",
        "        >>> pipeline['extrair_substantivos']('O produto é bom')\n",
        "        ['produto']\n",
        "    \"\"\"\n",
        "    pipeline = {\n",
        "        \"limpar\": limpar_texto,\n",
        "        \"tokenizar\": tokenizar,\n",
        "        \"remover_stopwords\": remover_stopwords,\n",
        "        \"aplicar_stemming\": aplicar_stemming,\n",
        "        \"preprocessar\": preprocessar_texto,\n",
        "        \"processar_lote\": processar_lote,\n",
        "        \"analisar_frequencia\": analisar_frequencia,\n",
        "        \"extrair_pos_tags\": extrair_pos_tags,\n",
        "        \"extrair_substantivos\": extrair_substantivos,\n",
        "        \"extrair_adjetivos\": extrair_adjetivos,\n",
        "        \"extrair_verbos\": extrair_verbos,\n",
        "    }\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "# === CRIAR PIPELINE E TESTAR ===\n",
        "# Não modifique os nomes das variáveis abaixo\n",
        "\n",
        "pipeline_final_q12 = criar_pipeline_preprocessamento()\n",
        "\n",
        "# Testar usando o pipeline\n",
        "texto_teste_q12 = \"O PRODUTO chegou muito rápido!!! Excelente qualidade.\"\n",
        "resultado_nltk_q12 = pipeline_final_q12[\"preprocessar\"](texto_teste_q12)\n",
        "resultado_spacy_q12 = pipeline_final_q12[\"extrair_adjetivos\"](texto_teste_q12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pln01ent_q12_validation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06ba941-5afc-495e-88d9-4db95f4117bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "VALIDAÇÃO Q12: criar_pipeline_preprocessamento\n",
            "============================================================\n",
            "\n",
            "Estrutura do pipeline:\n",
            "  Tipo: dict\n",
            "  Número de funções: 11\n",
            "\n",
            "Verificação de funções:\n",
            "  ✓ limpar                   : existe=True, callable=True\n",
            "  ✓ tokenizar                : existe=True, callable=True\n",
            "  ✓ remover_stopwords        : existe=True, callable=True\n",
            "  ✓ aplicar_stemming         : existe=True, callable=True\n",
            "  ✓ preprocessar             : existe=True, callable=True\n",
            "  ✓ processar_lote           : existe=True, callable=True\n",
            "  ✓ analisar_frequencia      : existe=True, callable=True\n",
            "  ✓ extrair_pos_tags         : existe=True, callable=True\n",
            "  ✓ extrair_substantivos     : existe=True, callable=True\n",
            "  ✓ extrair_adjetivos        : existe=True, callable=True\n",
            "  ✓ extrair_verbos           : existe=True, callable=True\n",
            "\n",
            "Teste funcional:\n",
            "  Entrada: 'O PRODUTO chegou muito rápido!!! Excelente qualidade.'\n",
            "  NLTK preprocessar: 'produt cheg rápid excel qual'\n",
            "  spaCy adjetivos: ['rápido', 'excelente']\n"
          ]
        }
      ],
      "source": [
        "# Validação da Q12 - Execute para verificar sua implementação\n",
        "print(\"=\" * 60)\n",
        "print(\"VALIDAÇÃO Q12: criar_pipeline_preprocessamento\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verificar estrutura do pipeline\n",
        "print(f\"\\nEstrutura do pipeline:\")\n",
        "print(f\"  Tipo: {type(pipeline_final_q12).__name__}\")\n",
        "print(f\"  Número de funções: {len(pipeline_final_q12)}\")\n",
        "\n",
        "# Verificar se todas as funções estão presentes\n",
        "print(f\"\\nVerificação de funções:\")\n",
        "chaves_esperadas = [\n",
        "    'limpar', 'tokenizar', 'remover_stopwords', 'aplicar_stemming',\n",
        "    'preprocessar', 'processar_lote', 'analisar_frequencia',\n",
        "    'extrair_pos_tags', 'extrair_substantivos', 'extrair_adjetivos', 'extrair_verbos'\n",
        "]\n",
        "for chave in chaves_esperadas:\n",
        "    existe = chave in pipeline_final_q12\n",
        "    callable_ok = callable(pipeline_final_q12.get(chave)) if existe else False\n",
        "    status = \"✓\" if (existe and callable_ok) else \"✗\"\n",
        "    print(f\"  {status} {chave:25s}: existe={existe}, callable={callable_ok}\")\n",
        "\n",
        "# Teste funcional\n",
        "print(f\"\\nTeste funcional:\")\n",
        "print(f\"  Entrada: '{texto_teste_q12}'\")\n",
        "print(f\"  NLTK preprocessar: '{resultado_nltk_q12}'\")\n",
        "print(f\"  spaCy adjetivos: {resultado_spacy_q12}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_summary"
      },
      "source": [
        "---\n",
        "\n",
        "## Resumo das Funções Implementadas\n",
        "\n",
        "| Função | Descrição | Uso no Chatbot |\n",
        "|--------|-----------|----------------|\n",
        "| **NLTK - Pré-processamento** | | |\n",
        "| `limpar_texto` | Limpeza básica | Pré-processamento de mensagens |\n",
        "| `tokenizar` | Tokenização NLTK | Análise de tokens |\n",
        "| `remover_stopwords` | Remove stopwords | Redução de ruído |\n",
        "| `aplicar_stemming` | Stemming RSLP | Normalização |\n",
        "| `preprocessar_texto` | Pipeline completo | **Principal** - usado em todas as etapas |\n",
        "| `processar_lote` | Processamento em lote | Treinar classificador |\n",
        "| `analisar_frequencia` | Contagem de termos | Análise exploratória |\n",
        "| **spaCy - Análise Linguística** | | |\n",
        "| `extrair_pos_tags` | Classes gramaticais | Análise morfossintática |\n",
        "| `extrair_substantivos` | Substantivos (lemas) | Identificar tópicos/produtos |\n",
        "| `extrair_adjetivos` | Adjetivos (lemas) | **Análise de sentimento** |\n",
        "| `extrair_verbos` | Verbos (lemas) | Identificar ações do cliente |\n",
        "| **Integração** | | |\n",
        "| `criar_pipeline_preprocessamento` | Exporta funções | Integração com outras entregas |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pln01ent_footer"
      },
      "source": [
        "---\n",
        "\n",
        "## Checklist de Entrega\n",
        "\n",
        "Antes de enviar, verifique:\n",
        "\n",
        "- [ ] Todas as funções estão implementadas\n",
        "- [ ] Todas as células foram executadas em ordem\n",
        "- [ ] Os nomes das funções não foram alterados\n",
        "- [ ] O código está comentado\n",
        "- [ ] Os testes básicos passaram\n",
        "\n",
        "---\n",
        "\n",
        "## Submissão\n",
        "\n",
        "1. Verifique se todas as células foram executadas em ordem\n",
        "2. Confira se não há erros de execução\n",
        "3. Limpe as células de saída (Edit > Clear all outputs)\n",
        "4. Salve o notebook (Ctrl+S ou File > Save)\n",
        "5. Faça download do arquivo .ipynb\n",
        "6. Submeta no Moodle até a data limite\n",
        "\n",
        "**Envie este notebook via Moodle até a data limite.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}